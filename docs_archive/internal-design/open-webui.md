# Open WebUI - å†…éƒ¨è®¾è®¡æ–‡æ¡£

## ğŸ“‹ åŸºæœ¬ä¿¡æ¯

- **æ¨¡å—åç§°**: Open WebUI (AIæ¨¡å‹ç®¡ç†ç•Œé¢)
- **æŠ€æœ¯æ ˆ**: Open WebUI + Docker + Ollamaé›†æˆ
- **éƒ¨ç½²ç«¯å£**: 3001
- **ä¾æ®**: å¤–éƒ¨è®¾è®¡æ–‡æ¡£è§„èŒƒ

---

## ğŸ“ æ–‡ä»¶ç»“æ„å’Œæƒé™

```
/home/wyatt/prism2/open-webui/
â”œâ”€â”€ docker-compose.yml                    # Dockerç¼–æ’é…ç½® (644)
â”œâ”€â”€ .env                                  # ç¯å¢ƒå˜é‡ (600)
â”œâ”€â”€ config/                               # é…ç½®ç›®å½• (755)
â”‚   â”œâ”€â”€ nginx.conf                        # Nginxé…ç½® (644)
â”‚   â”œâ”€â”€ auth_config.json                  # è®¤è¯é…ç½® (644)
â”‚   â””â”€â”€ model_config.json                 # æ¨¡å‹é…ç½® (644)
â”œâ”€â”€ data/                                 # æ•°æ®æŒä¹…åŒ–ç›®å½• (755)
â”‚   â”œâ”€â”€ database/                         # æ•°æ®åº“æ–‡ä»¶ (755)
â”‚   â”œâ”€â”€ uploads/                          # æ–‡ä»¶ä¸Šä¼  (755)
â”‚   â””â”€â”€ logs/                             # æ—¥å¿—æ–‡ä»¶ (755)
â”œâ”€â”€ customizations/                       # è‡ªå®šä¹‰é…ç½® (755)
â”‚   â”œâ”€â”€ themes/                           # ä¸»é¢˜æ ·å¼ (755)
â”‚   â”‚   â””â”€â”€ prism2-theme.css             # è‡ªå®šä¹‰ä¸»é¢˜ (644)
â”‚   â”œâ”€â”€ prompts/                          # é¢„è®¾æç¤ºè¯ (755)
â”‚   â”‚   â”œâ”€â”€ financial_analysis.json      # é‡‘èåˆ†ææç¤ºè¯ (644)
â”‚   â”‚   â”œâ”€â”€ stock_research.json          # è‚¡ç¥¨ç ”ç©¶æç¤ºè¯ (644)
â”‚   â”‚   â””â”€â”€ investment_advice.json       # æŠ•èµ„å»ºè®®æç¤ºè¯ (644)
â”‚   â””â”€â”€ models/                           # æ¨¡å‹ç®¡ç†è„šæœ¬ (755)
â”‚       â”œâ”€â”€ model_downloader.py          # æ¨¡å‹ä¸‹è½½è„šæœ¬ (755)
â”‚       â””â”€â”€ model_validator.py           # æ¨¡å‹éªŒè¯è„šæœ¬ (755)
â”œâ”€â”€ scripts/                              # è¿ç»´è„šæœ¬ (755)
â”‚   â”œâ”€â”€ backup.sh                         # æ•°æ®å¤‡ä»½è„šæœ¬ (755)
â”‚   â”œâ”€â”€ restore.sh                        # æ•°æ®æ¢å¤è„šæœ¬ (755)
â”‚   â””â”€â”€ health_check.sh                   # å¥åº·æ£€æŸ¥è„šæœ¬ (755)
â””â”€â”€ README.md                            # éƒ¨ç½²è¯´æ˜ (644)
```

---

## ğŸ³ Dockerå®¹å™¨é…ç½®

### Docker Composeé…ç½® (docker-compose.yml)
```yaml
version: '3.8'

services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: prism2-open-webui
    restart: unless-stopped
    ports:
      - "3001:8080"
    environment:
      # åŸºç¡€é…ç½®
      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY}
      - WEBUI_NAME=Prism2 AI Lab
      - WEBUI_URL=http://localhost:3001

      # Ollamaè¿æ¥é…ç½®
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      - ENABLE_OLLAMA_API=true

      # === å¤–éƒ¨æœåŠ¡é›†æˆé…ç½® ===
      - STOCK_SERVICE_URL=http://host.docker.internal:8000
      - RAG_SERVICE_URL=http://host.docker.internal:8001
      - AUTH_SERVICE_URL=http://host.docker.internal:8004
      - NEWS_SERVICE_URL=http://host.docker.internal:8005

      # RAGå¢å¼ºåŠŸèƒ½é…ç½®
      - ENABLE_RAG_ENHANCED_CHAT=true
      - RAG_CONTEXT_LIMIT=5
      - ENABLE_REALTIME_DATA=true
      - ENABLE_NEWS_INTEGRATION=true

      # è®¤è¯é…ç½®
      - ENABLE_SIGNUP=${ENABLE_SIGNUP:-false}
      - DEFAULT_USER_ROLE=${DEFAULT_USER_ROLE:-user}
      - ENABLE_LOGIN_FORM=true
      - ENABLE_EXTERNAL_AUTH=true

      # åŠŸèƒ½é…ç½® (è°ƒæ•´ä¸ºé‡‘èåœºæ™¯)
      - ENABLE_MODEL_FILTER=true
      - ENABLE_WEB_SEARCH=false
      - ENABLE_IMAGE_GENERATION=false
      - ENABLE_COMMUNITY_SHARING=false
      - ENABLE_STOCK_ANALYSIS_MODE=true

      # å­˜å‚¨é…ç½®
      - DATA_DIR=/app/backend/data
      - UPLOAD_DIR=/app/backend/data/uploads

      # è‡ªå®šä¹‰é…ç½®
      - CUSTOM_THEME_PATH=/app/backend/data/themes
      - DEFAULT_PROMPT_TEMPLATE_PATH=/app/backend/data/prompts

    volumes:
      # æ•°æ®æŒä¹…åŒ–
      - ./data:/app/backend/data

      # è‡ªå®šä¹‰é…ç½®
      - ./customizations/themes:/app/backend/data/themes:ro
      - ./customizations/prompts:/app/backend/data/prompts:ro

      # é…ç½®æ–‡ä»¶
      - ./config/auth_config.json:/app/backend/data/config/auth_config.json:ro

    networks:
      - prism2-network

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Nginxåå‘ä»£ç† (å¯é€‰)
  nginx:
    image: nginx:alpine
    container_name: prism2-webui-nginx
    restart: unless-stopped
    ports:
      - "3001:80"
    volumes:
      - ./config/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - open-webui
    networks:
      - prism2-network
    profiles:
      - "with-nginx"

networks:
  prism2-network:
    external: true
    name: prism2_default

volumes:
  webui_data:
    driver: local
```

---

## ğŸ”§ æ ¸å¿ƒé…ç½®ç®¡ç†

### æ¨¡å‹é…ç½® (config/model_config.json)
```json
{
  "default_models": {
    "primary": "qwen2.5:7b",
    "fallback": "deepseek-coder:1.3b"
  },
  "model_settings": {
    "qwen2.5:7b": {
      "display_name": "Qwen2.5-7B (é€šç”¨åˆ†æ)",
      "description": "é€‚ç”¨äºç»¼åˆé‡‘èåˆ†æå’ŒæŠ•èµ„å»ºè®®",
      "default_parameters": {
        "temperature": 0.7,
        "top_p": 0.9,
        "max_tokens": 2048,
        "context_length": 8192
      },
      "system_prompts": {
        "default": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆï¼Œå…·æœ‰ä¸°å¯Œçš„è‚¡ç¥¨æŠ•èµ„ç»éªŒã€‚è¯·åŸºäºæä¾›çš„ä¿¡æ¯ç»™å‡ºå®¢è§‚ã€ä¸“ä¸šçš„åˆ†æå»ºè®®ã€‚",
        "technical": "ä½ æ˜¯æŠ€æœ¯åˆ†æä¸“å®¶ï¼Œä¸“æ³¨äºKçº¿å›¾è¡¨ã€æŠ€æœ¯æŒ‡æ ‡åˆ†æå’Œå¸‚åœºè¶‹åŠ¿åˆ¤æ–­ã€‚",
        "fundamental": "ä½ æ˜¯åŸºæœ¬é¢åˆ†æä¸“å®¶ï¼Œä¸“æ³¨äºè´¢åŠ¡æŠ¥è¡¨åˆ†æã€å…¬å¸ä¼°å€¼å’Œè¡Œä¸šæ¯”è¾ƒã€‚"
      },
      "use_cases": ["æŠ•èµ„åˆ†æ", "å¸‚åœºé¢„æµ‹", "é£é™©è¯„ä¼°", "ç­–ç•¥å»ºè®®"]
    },
    "deepseek-coder:1.3b": {
      "display_name": "DeepSeek-Coder-1.3B (ä»£ç ç”Ÿæˆ)",
      "description": "ä¸“é—¨ç”¨äºä»£ç ç”Ÿæˆå’ŒæŠ€æœ¯å®ç°",
      "default_parameters": {
        "temperature": 0.3,
        "top_p": 0.8,
        "max_tokens": 1024,
        "context_length": 4096
      },
      "system_prompts": {
        "default": "ä½ æ˜¯ä¸€ä½èµ„æ·±ç¨‹åºå‘˜ï¼Œä¸“æ³¨äºPythonå’ŒJavaScriptå¼€å‘ã€‚è¯·æä¾›æ¸…æ™°ã€é«˜æ•ˆçš„ä»£ç è§£å†³æ–¹æ¡ˆã€‚",
        "financial": "ä½ æ˜¯é‡‘èç§‘æŠ€å¼€å‘ä¸“å®¶ï¼Œç†Ÿæ‚‰é‡‘èæ•°æ®å¤„ç†å’Œé‡åŒ–åˆ†æç¼–ç¨‹ã€‚"
      },
      "use_cases": ["ä»£ç ç”Ÿæˆ", "ç®—æ³•å®ç°", "æ•°æ®å¤„ç†", "APIå¼€å‘"]
    }
  },
  "auto_load_models": true,
  "model_timeout": 300,
  "concurrent_requests": 5
}
```

### è®¤è¯é…ç½® (config/auth_config.json)
```json
{
  "authentication": {
    "method": "local",
    "session_duration": 86400,
    "enable_registration": false,
    "require_email_verification": false
  },
  "default_users": [
    {
      "email": "admin@prism2.local",
      "name": "Prism2 Admin",
      "role": "admin",
      "password_hash": "$2b$12$..."
    }
  ],
  "user_roles": {
    "admin": {
      "permissions": ["model:manage", "user:manage", "system:config"],
      "model_access": ["all"],
      "rate_limits": {
        "requests_per_minute": 100,
        "max_tokens_per_day": 50000
      }
    },
    "user": {
      "permissions": ["chat:create", "model:use"],
      "model_access": ["qwen2.5:7b"],
      "rate_limits": {
        "requests_per_minute": 20,
        "max_tokens_per_day": 10000
      }
    },
    "guest": {
      "permissions": ["chat:read"],
      "model_access": [],
      "rate_limits": {
        "requests_per_minute": 5,
        "max_tokens_per_day": 1000
      }
    }
  },
  "security": {
    "session_secret": "your-session-secret-key",
    "csrf_protection": true,
    "rate_limiting": true,
    "ip_whitelist": []
  }
}
```

---

## ğŸ¨ ç•Œé¢è‡ªå®šä¹‰é…ç½®

### è‡ªå®šä¹‰ä¸»é¢˜ (customizations/themes/prism2-theme.css)
```css
/* Prism2 ä¸“ç”¨ä¸»é¢˜æ ·å¼ */
:root {
  /* ä¸»è‰²è°ƒ - é‡‘èè“ */
  --primary-color: #1e3a8a;
  --primary-light: #3b82f6;
  --primary-dark: #1e40af;

  /* è¾…åŠ©è‰²è°ƒ */
  --success-color: #059669;  /* æ¶¨å¹…ç»¿ */
  --danger-color: #dc2626;   /* è·Œå¹…çº¢ */
  --warning-color: #d97706;  /* è­¦å‘Šæ©™ */
  --info-color: #0891b2;     /* ä¿¡æ¯é’ */

  /* èƒŒæ™¯è‰² */
  --bg-primary: #ffffff;
  --bg-secondary: #f8fafc;
  --bg-tertiary: #e2e8f0;

  /* æ–‡å­—è‰² */
  --text-primary: #1f2937;
  --text-secondary: #6b7280;
  --text-muted: #9ca3af;

  /* è¾¹æ¡†å’Œé˜´å½± */
  --border-color: #e5e7eb;
  --shadow-sm: 0 1px 2px 0 rgb(0 0 0 / 0.05);
  --shadow-md: 0 4px 6px -1px rgb(0 0 0 / 0.1);
}

/* é¡¶éƒ¨å¯¼èˆªæ  */
.navbar {
  background: linear-gradient(135deg, var(--primary-color), var(--primary-light));
  border-bottom: 1px solid var(--border-color);
}

.navbar-brand {
  font-weight: 700;
  color: white !important;
}

.navbar-brand::before {
  content: "ğŸ”® ";
  margin-right: 0.5rem;
}

/* ä¾§è¾¹æ  */
.sidebar {
  background: var(--bg-secondary);
  border-right: 1px solid var(--border-color);
}

.sidebar .nav-item.active {
  background: var(--primary-light);
  color: white;
  border-radius: 0.375rem;
}

/* èŠå¤©ç•Œé¢ */
.chat-container {
  background: var(--bg-primary);
}

.message.user {
  background: var(--primary-light);
  color: white;
  border-radius: 1rem 1rem 0.25rem 1rem;
}

.message.assistant {
  background: var(--bg-secondary);
  color: var(--text-primary);
  border-radius: 1rem 1rem 1rem 0.25rem;
  border-left: 3px solid var(--primary-color);
}

/* æ¨¡å‹é€‰æ‹©å™¨ */
.model-selector {
  border: 2px solid var(--primary-light);
  border-radius: 0.5rem;
  background: var(--bg-primary);
}

.model-selector.active {
  background: var(--primary-light);
  color: white;
}

/* æŒ‰é’®æ ·å¼ */
.btn-primary {
  background: var(--primary-color);
  border-color: var(--primary-color);
}

.btn-primary:hover {
  background: var(--primary-dark);
  border-color: var(--primary-dark);
}

/* ä»£ç å—æ ·å¼ */
.code-block {
  background: #1f2937;
  color: #f9fafb;
  border-radius: 0.5rem;
  border-left: 4px solid var(--primary-light);
}

/* å“åº”å¼è®¾è®¡ */
@media (max-width: 768px) {
  .sidebar {
    transform: translateX(-100%);
    transition: transform 0.3s ease;
  }

  .sidebar.open {
    transform: translateX(0);
  }
}

/* æ»šåŠ¨æ¡æ ·å¼ */
::-webkit-scrollbar {
  width: 8px;
}

::-webkit-scrollbar-track {
  background: var(--bg-secondary);
}

::-webkit-scrollbar-thumb {
  background: var(--primary-light);
  border-radius: 4px;
}

::-webkit-scrollbar-thumb:hover {
  background: var(--primary-dark);
}
```

---

## ğŸ“ é¢„è®¾æç¤ºè¯åº“

### é‡‘èåˆ†ææç¤ºè¯ (customizations/prompts/financial_analysis.json)
```json
{
  "name": "financial_analysis_prompts",
  "version": "1.0",
  "prompts": [
    {
      "id": "comprehensive_analysis",
      "title": "ç»¼åˆæŠ•èµ„åˆ†æ",
      "category": "investment",
      "system_prompt": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„é‡‘èæŠ•èµ„åˆ†æå¸ˆï¼Œæ‹¥æœ‰15å¹´çš„Aè‚¡å’Œæ¸¯è‚¡æŠ•èµ„ç»éªŒã€‚è¯·åŸºäºæä¾›çš„è‚¡ç¥¨ä¿¡æ¯ï¼Œä»æŠ€æœ¯é¢ã€åŸºæœ¬é¢ã€æ¶ˆæ¯é¢ä¸‰ä¸ªç»´åº¦è¿›è¡Œå…¨é¢åˆ†æï¼Œå¹¶ç»™å‡ºæ˜ç¡®çš„æŠ•èµ„å»ºè®®å’Œé£é™©æç¤ºã€‚",
      "user_template": "è¯·åˆ†æè‚¡ç¥¨ {stock_code} ({stock_name}) çš„æŠ•èµ„ä»·å€¼ã€‚\n\nå½“å‰ä¿¡æ¯ï¼š\n- è‚¡ä»·ï¼š{current_price}\n- æ¶¨è·Œå¹…ï¼š{change_percent}%\n- å¸‚å€¼ï¼š{market_cap}\n- PEï¼š{pe_ratio}\n- æœ€æ–°è´¢æŠ¥ï¼š{latest_financial}\n\nè¯·ç»™å‡ºè¯¦ç»†çš„æŠ•èµ„åˆ†ææŠ¥å‘Šã€‚",
      "parameters": {
        "temperature": 0.7,
        "max_tokens": 2048
      }
    },
    {
      "id": "technical_analysis",
      "title": "æŠ€æœ¯åˆ†æ",
      "category": "technical",
      "system_prompt": "ä½ æ˜¯ä¸“ä¸šçš„æŠ€æœ¯åˆ†æå¸ˆï¼Œç²¾é€šå„ç§æŠ€æœ¯æŒ‡æ ‡å’Œå›¾è¡¨åˆ†æã€‚è¯·åŸºäºKçº¿æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡ï¼Œåˆ†æè‚¡ç¥¨çš„æŠ€æœ¯èµ°åŠ¿ï¼Œè¯†åˆ«æ”¯æ’‘é˜»åŠ›ä½ï¼Œåˆ¤æ–­è¶‹åŠ¿æ–¹å‘ã€‚",
      "user_template": "è¯·å¯¹è‚¡ç¥¨ {stock_code} è¿›è¡ŒæŠ€æœ¯åˆ†æï¼š\n\nKçº¿æ•°æ®ï¼š{kline_data}\næŠ€æœ¯æŒ‡æ ‡ï¼š{technical_indicators}\n\nè¯·åˆ†æï¼š\n1. å½“å‰è¶‹åŠ¿æ–¹å‘\n2. å…³é”®æ”¯æ’‘é˜»åŠ›ä½\n3. ä¹°å–ç‚¹å»ºè®®\n4. é£é™©æ§åˆ¶ç­–ç•¥",
      "parameters": {
        "temperature": 0.6,
        "max_tokens": 1536
      }
    },
    {
      "id": "fundamental_analysis",
      "title": "åŸºæœ¬é¢åˆ†æ",
      "category": "fundamental",
      "system_prompt": "ä½ æ˜¯åŸºæœ¬é¢åˆ†æä¸“å®¶ï¼Œä¸“æ³¨äºè´¢åŠ¡æŠ¥è¡¨åˆ†æã€è¡Œä¸šæ¯”è¾ƒå’Œä¼°å€¼ç ”ç©¶ã€‚è¯·æ·±å…¥åˆ†æå…¬å¸çš„ç›ˆåˆ©èƒ½åŠ›ã€æˆé•¿æ€§ã€è´¢åŠ¡å¥åº·åº¦å’Œä¼°å€¼æ°´å¹³ã€‚",
      "user_template": "è¯·åˆ†æ {company_name} ({stock_code}) çš„åŸºæœ¬é¢ï¼š\n\nè´¢åŠ¡æ•°æ®ï¼š{financial_data}\nè¡Œä¸šä¿¡æ¯ï¼š{industry_info}\nç«äº‰å¯¹æ‰‹ï¼š{competitors}\n\nè¯·é‡ç‚¹åˆ†æï¼š\n1. ç›ˆåˆ©èƒ½åŠ›å’Œæˆé•¿æ€§\n2. è´¢åŠ¡å¥åº·çŠ¶å†µ\n3. ä¼°å€¼æ°´å¹³\n4. è¡Œä¸šåœ°ä½å’Œç«äº‰ä¼˜åŠ¿",
      "parameters": {
        "temperature": 0.5,
        "max_tokens": 2048
      }
    },
    {
      "id": "risk_assessment",
      "title": "é£é™©è¯„ä¼°",
      "category": "risk",
      "system_prompt": "ä½ æ˜¯é£é™©ç®¡ç†ä¸“å®¶ï¼Œä¸“é—¨è¯†åˆ«å’Œè¯„ä¼°æŠ•èµ„é£é™©ã€‚è¯·å…¨é¢åˆ†æè‚¡ç¥¨æŠ•èµ„çš„å„ç±»é£é™©ï¼Œå¹¶æä¾›é£é™©æ§åˆ¶å»ºè®®ã€‚",
      "user_template": "è¯·è¯„ä¼°è‚¡ç¥¨ {stock_code} çš„æŠ•èµ„é£é™©ï¼š\n\nå…¬å¸ä¿¡æ¯ï¼š{company_info}\nå¸‚åœºç¯å¢ƒï¼š{market_environment}\nè¿‘æœŸæ–°é—»ï¼š{recent_news}\n\nè¯·åˆ†æï¼š\n1. ç³»ç»Ÿæ€§é£é™©\n2. éç³»ç»Ÿæ€§é£é™©\n3. æµåŠ¨æ€§é£é™©\n4. é£é™©æ§åˆ¶ç­–ç•¥",
      "parameters": {
        "temperature": 0.4,
        "max_tokens": 1536
      }
    }
  ]
}
```

### è‚¡ç¥¨ç ”ç©¶æç¤ºè¯ (customizations/prompts/stock_research.json)
```json
{
  "name": "stock_research_prompts",
  "version": "1.0",
  "prompts": [
    {
      "id": "company_profile",
      "title": "å…¬å¸ç ”ç©¶æŠ¥å‘Š",
      "category": "research",
      "system_prompt": "ä½ æ˜¯ä¸“ä¸šçš„è‚¡ç¥¨ç ”ç©¶åˆ†æå¸ˆï¼Œæ“…é•¿æ’°å†™æ·±åº¦ç ”ç©¶æŠ¥å‘Šã€‚è¯·åŸºäºå…¬å¸ä¿¡æ¯ï¼Œæ’°å†™ç»“æ„æ¸…æ™°ã€é€»è¾‘ä¸¥å¯†çš„ç ”ç©¶æŠ¥å‘Šã€‚",
      "user_template": "è¯·ä¸º {company_name} æ’°å†™ç ”ç©¶æŠ¥å‘Šï¼š\n\nå…¬å¸åŸºæœ¬ä¿¡æ¯ï¼š{basic_info}\nä¸šåŠ¡æ¨¡å¼ï¼š{business_model}\nè´¢åŠ¡æ•°æ®ï¼š{financial_data}\n\næŠ¥å‘Šç»“æ„ï¼š\n1. å…¬å¸æ¦‚å†µ\n2. ä¸šåŠ¡åˆ†æ\n3. è´¢åŠ¡åˆ†æ\n4. ç«äº‰åŠ›è¯„ä¼°\n5. æŠ•èµ„è¯„çº§",
      "parameters": {
        "temperature": 0.6,
        "max_tokens": 3072
      }
    },
    {
      "id": "industry_analysis",
      "title": "è¡Œä¸šåˆ†æ",
      "category": "industry",
      "system_prompt": "ä½ æ˜¯è¡Œä¸šç ”ç©¶ä¸“å®¶ï¼Œå¯¹å„ä¸ªè¡Œä¸šçš„å‘å±•è¶‹åŠ¿ã€ç«äº‰æ ¼å±€ã€æ”¿ç­–å½±å“æœ‰æ·±å…¥äº†è§£ã€‚è¯·åˆ†æè¡Œä¸šç°çŠ¶å’Œå‰æ™¯ã€‚",
      "user_template": "è¯·åˆ†æ {industry_name} è¡Œä¸šï¼š\n\nè¡Œä¸šæ•°æ®ï¼š{industry_data}\næ”¿ç­–ç¯å¢ƒï¼š{policy_environment}\nä¸»è¦å…¬å¸ï¼š{major_companies}\n\nè¯·åˆ†æï¼š\n1. è¡Œä¸šå‘å±•è¶‹åŠ¿\n2. ç«äº‰æ ¼å±€\n3. æŠ•èµ„æœºä¼š\n4. é£é™©å› ç´ ",
      "parameters": {
        "temperature": 0.7,
        "max_tokens": 2048
      }
    }
  ]
}
```

---

## ğŸ”Œ APIæ¥å£é›†æˆ (ä¸¥æ ¼æŒ‰ç…§å¤–éƒ¨è®¾è®¡)

### æ ¸å¿ƒæ¥å£å®šä¹‰ (éµå¾ªå¤–éƒ¨è®¾è®¡è§„èŒƒ)
```python
# === RAGå¢å¼ºèŠå¤©æ¥å£ (æ ¸å¿ƒåŠŸèƒ½) ===
class EnhancedChatRequest(BaseModel):
    message: str                           # ç”¨æˆ·æ¶ˆæ¯
    stock_context: str = None              # è‚¡ç¥¨ä»£ç ä¸Šä¸‹æ–‡
    enable_rag: bool = True                # å¯ç”¨RAGå¢å¼º
    enable_realtime: bool = True           # å¯ç”¨å®æ—¶æ•°æ®
    model: str = "qwen2.5:7b"             # ä½¿ç”¨çš„æ¨¡å‹
    system_prompt: str = None              # è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯
    temperature: float = 0.7               # æ¸©åº¦å‚æ•°
    max_tokens: int = 2048                 # æœ€å¤§tokenæ•°

class EnhancedChatResponse(BaseModel):
    response: str                          # AIå›å¤
    data_sources: List[str]                # ä½¿ç”¨çš„æ•°æ®æº
    rag_context: List[str] = []           # RAGæ£€ç´¢çš„ä¸Šä¸‹æ–‡
    realtime_data: Dict = {}               # å®æ—¶æ•°æ®
    confidence: float                      # å›å¤ç½®ä¿¡åº¦
    model_used: str                        # ä½¿ç”¨çš„æ¨¡å‹

# === è‚¡ç¥¨æŸ¥è¯¢é›†æˆæ¥å£ ===
class StockQueryRequest(BaseModel):
    query: str                             # è‚¡ç¥¨æŸ¥è¯¢ (ä»£ç /åç§°)
    analysis_type: List[str] = ["basic"]   # ["basic", "technical", "fundamental"]
    include_news: bool = True              # åŒ…å«ç›¸å…³æ–°é—»

class StockQueryResponse(BaseModel):
    stock_info: Dict                       # åŸºç¡€è‚¡ç¥¨ä¿¡æ¯
    analysis_data: Dict = {}               # åˆ†ææ•°æ®
    related_news: List[Dict] = []          # ç›¸å…³æ–°é—»
    ai_summary: str                        # AIç”Ÿæˆçš„æ€»ç»“

# === æ¨¡å‹ç®¡ç†æ¥å£ ===
class ModelSwitchRequest(BaseModel):
    model_name: str                        # "qwen2.5:7b" | "deepseek-coder:1.3b"
    force_reload: bool = False             # æ˜¯å¦å¼ºåˆ¶é‡æ–°åŠ è½½

class ChatRequest(BaseModel):
    message: str                           # ç”¨æˆ·æ¶ˆæ¯
    model: str                             # ä½¿ç”¨çš„æ¨¡å‹
    system_prompt: str                     # ç³»ç»Ÿæç¤ºè¯
    temperature: float = 0.7               # æ¸©åº¦å‚æ•°
    max_tokens: int = 2048                 # æœ€å¤§tokenæ•°
```

### WebUIæ ¸å¿ƒåŠŸèƒ½ç«¯ç‚¹
```python
# === RAGå¢å¼ºå¯¹è¯ (ä¸»è¦åŠŸèƒ½) ===
POST /api/chat/enhanced                   # RAGå¢å¼ºå¯¹è¯
POST /api/chat/stock-analysis            # è‚¡ç¥¨åˆ†æå¯¹è¯
POST /api/chat/news-summary              # æ–°é—»æ€»ç»“å¯¹è¯

# === å¤–éƒ¨æœåŠ¡é›†æˆç«¯ç‚¹ ===
GET  /api/integration/stock/{code}        # è·å–è‚¡ç¥¨ä¿¡æ¯
GET  /api/integration/news/latest        # è·å–æœ€æ–°æ–°é—»
POST /api/integration/rag/search         # RAGè¯­ä¹‰æœç´¢

# === ä¼ ç»Ÿæ¨¡å‹ç®¡ç† ===
GET  /api/models                          # è·å–æ¨¡å‹åˆ—è¡¨
POST /api/models/switch                   # åˆ‡æ¢æ¨¡å‹
POST /api/models/pull                     # ä¸‹è½½æ¨¡å‹
DELETE /api/models/{model_name}           # åˆ é™¤æ¨¡å‹

# === å¯¹è¯ç®¡ç† ===
GET  /api/chats                           # è·å–å¯¹è¯åˆ—è¡¨
POST /api/chats                           # åˆ›å»ºæ–°å¯¹è¯
GET  /api/chats/{chat_id}                 # è·å–å¯¹è¯è¯¦æƒ…
DELETE /api/chats/{chat_id}               # åˆ é™¤å¯¹è¯

# === æ¶ˆæ¯ç”Ÿæˆ ===
POST /api/generate                        # ç”Ÿæˆå›å¤
POST /api/chat/completions                # å…¼å®¹OpenAIæ ¼å¼

# === ç”¨æˆ·ç®¡ç† ===
POST /auth/signin                         # ç”¨æˆ·ç™»å½•
POST /auth/signup                         # ç”¨æˆ·æ³¨å†Œ
GET  /api/users/profile                   # è·å–ç”¨æˆ·ä¿¡æ¯
POST /api/settings                        # ä¿å­˜è®¾ç½®
```

### å¤–éƒ¨æœåŠ¡é›†æˆé…ç½®
```python
# === å¤–éƒ¨æœåŠ¡URLé…ç½® ===
EXTERNAL_SERVICES = {
    "stock_service": "http://host.docker.internal:8000",
    "rag_service": "http://host.docker.internal:8001",
    "auth_service": "http://host.docker.internal:8004",
    "news_service": "http://host.docker.internal:8005",
    "ollama_service": "http://host.docker.internal:11434"
}

# === APIé›†æˆé…ç½® ===
class ExternalAPIConfig:
    # Stock Serviceé›†æˆ
    STOCK_SEARCH_ENDPOINT = "/api/stock/search"
    STOCK_REALTIME_ENDPOINT = "/api/stock/{code}/realtime"
    STOCK_ANALYSIS_ENDPOINT = "/api/stock/analysis"

    # RAG Serviceé›†æˆ
    RAG_SEARCH_ENDPOINT = "/api/rag/search"
    RAG_CONTEXT_ENDPOINT = "/api/rag/context"

    # News Serviceé›†æˆ
    NEWS_LATEST_ENDPOINT = "/api/news/feed"
    NEWS_SEARCH_ENDPOINT = "/api/news/search"

    # Authenticationé›†æˆ
    AUTH_CHECK_ENDPOINT = "/api/auth/check-permission"
    USER_PROFILE_ENDPOINT = "/api/auth/profile"
```

---

## ğŸ§  RAGå¢å¼ºå¯¹è¯æ ¸å¿ƒé€»è¾‘

### å¢å¼ºå¯¹è¯å¤„ç†æµç¨‹
```python
"""
Open WebUI RAGå¢å¼ºå¯¹è¯æ ¸å¿ƒå®ç°é€»è¾‘
"""

class EnhancedChatHandler:
    def __init__(self):
        self.stock_service_client = HTTPClient(EXTERNAL_SERVICES["stock_service"])
        self.rag_service_client = HTTPClient(EXTERNAL_SERVICES["rag_service"])
        self.news_service_client = HTTPClient(EXTERNAL_SERVICES["news_service"])
        self.ollama_client = OllamaClient(EXTERNAL_SERVICES["ollama_service"])

    async def process_enhanced_chat(self, request: EnhancedChatRequest) -> EnhancedChatResponse:
        """
        RAGå¢å¼ºå¯¹è¯å¤„ç†ä¸»æµç¨‹:
        1. åˆ†æç”¨æˆ·æ¶ˆæ¯ï¼Œè¯†åˆ«è‚¡ç¥¨ç›¸å…³å†…å®¹
        2. å¦‚æœæ¶‰åŠè‚¡ç¥¨ï¼Œè·å–å®æ—¶æ•°æ®
        3. ä½¿ç”¨RAGæ£€ç´¢ç›¸å…³èƒŒæ™¯ä¿¡æ¯
        4. è·å–ç›¸å…³æ–°é—»ä¿¡æ¯
        5. æ„å»ºå¢å¼ºä¸Šä¸‹æ–‡
        6. ç”ŸæˆAIå›å¤
        """

        # Step 1: æ¶ˆæ¯åˆ†æå’Œè‚¡ç¥¨è¯†åˆ«
        stock_codes = self._extract_stock_codes(request.message)

        # Step 2: å¹¶è¡Œè·å–å®æ—¶æ•°æ®
        realtime_data = {}
        if stock_codes and request.enable_realtime:
            realtime_data = await self._fetch_realtime_data(stock_codes)

        # Step 3: RAGèƒŒæ™¯ä¿¡æ¯æ£€ç´¢
        rag_context = []
        if request.enable_rag:
            rag_context = await self._fetch_rag_context(request.message, stock_codes)

        # Step 4: ç›¸å…³æ–°é—»è·å–
        related_news = []
        if stock_codes:
            related_news = await self._fetch_related_news(stock_codes)

        # Step 5: æ„å»ºå¢å¼ºPrompt
        enhanced_prompt = self._build_enhanced_prompt(
            user_message=request.message,
            realtime_data=realtime_data,
            rag_context=rag_context,
            related_news=related_news,
            system_prompt=request.system_prompt
        )

        # Step 6: AIæ¨ç†ç”Ÿæˆå›å¤
        ai_response = await self._generate_ai_response(
            prompt=enhanced_prompt,
            model=request.model,
            temperature=request.temperature,
            max_tokens=request.max_tokens
        )

        # Step 7: æ„å»ºå¢å¼ºå“åº”
        return EnhancedChatResponse(
            response=ai_response.generated_text,
            data_sources=self._identify_data_sources(realtime_data, rag_context, related_news),
            rag_context=[doc.content for doc in rag_context],
            realtime_data=realtime_data,
            confidence=ai_response.confidence_score,
            model_used=ai_response.model_used
        )

    def _extract_stock_codes(self, message: str) -> List[str]:
        """ä»ç”¨æˆ·æ¶ˆæ¯ä¸­æå–è‚¡ç¥¨ä»£ç """
        # è‚¡ç¥¨ä»£ç è¯†åˆ«é€»è¾‘: æ­£åˆ™åŒ¹é… + NLPè¯†åˆ«
        import re
        codes = []

        # åŒ¹é…6ä½æ•°å­—è‚¡ç¥¨ä»£ç 
        code_patterns = re.findall(r'\b\d{6}\b', message)
        codes.extend(code_patterns)

        # TODO: æ·»åŠ è‚¡ç¥¨åç§°åˆ°ä»£ç çš„æ˜ å°„é€»è¾‘
        return codes

    async def _fetch_realtime_data(self, stock_codes: List[str]) -> Dict:
        """è·å–è‚¡ç¥¨å®æ—¶æ•°æ®"""
        realtime_data = {}

        for code in stock_codes:
            try:
                # è°ƒç”¨Stock Serviceè·å–å®æ—¶æ•°æ®
                response = await self.stock_service_client.get(
                    f"/api/stock/{code}/realtime"
                )
                if response.status_code == 200:
                    realtime_data[code] = response.json()
            except Exception as e:
                print(f"è·å–è‚¡ç¥¨{code}å®æ—¶æ•°æ®å¤±è´¥: {e}")

        return realtime_data

    async def _fetch_rag_context(self, message: str, stock_codes: List[str]) -> List[Dict]:
        """RAGä¸Šä¸‹æ–‡æ£€ç´¢"""
        try:
            # æ„å»ºRAGæœç´¢è¯·æ±‚
            search_query = message
            if stock_codes:
                # å¦‚æœæœ‰è‚¡ç¥¨ä»£ç ï¼Œæ„å»ºæ›´ç²¾ç¡®çš„æœç´¢æŸ¥è¯¢
                search_query = f"{message} {' '.join(stock_codes)}"

            # è°ƒç”¨RAG Serviceè¿›è¡Œè¯­ä¹‰æœç´¢
            response = await self.rag_service_client.post(
                "/api/rag/search",
                json={
                    "query": search_query,
                    "stock_codes": stock_codes,
                    "limit": 5,
                    "search_type": "semantic"
                }
            )

            if response.status_code == 200:
                return response.json().get("results", [])

        except Exception as e:
            print(f"RAGä¸Šä¸‹æ–‡æ£€ç´¢å¤±è´¥: {e}")

        return []

    async def _fetch_related_news(self, stock_codes: List[str]) -> List[Dict]:
        """è·å–ç›¸å…³æ–°é—»"""
        try:
            # è°ƒç”¨News Serviceè·å–ç›¸å…³æ–°é—»
            response = await self.news_service_client.get(
                "/api/news/feed",
                params={
                    "stock_codes": ",".join(stock_codes),
                    "limit": 3,
                    "sort": "publish_time"
                }
            )

            if response.status_code == 200:
                return response.json().get("items", [])

        except Exception as e:
            print(f"è·å–ç›¸å…³æ–°é—»å¤±è´¥: {e}")

        return []

    def _build_enhanced_prompt(self, user_message: str, realtime_data: Dict,
                             rag_context: List[Dict], related_news: List[Dict],
                             system_prompt: str = None) -> str:
        """æ„å»ºRAGå¢å¼ºçš„Prompt"""

        # åŸºç¡€ç³»ç»ŸPrompt
        base_system = system_prompt or """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆå’ŒæŠ•èµ„é¡¾é—®ï¼Œå…·æœ‰ä¸°å¯Œçš„è‚¡ç¥¨åˆ†æç»éªŒã€‚
è¯·åŸºäºæä¾›çš„å®æ—¶æ•°æ®ã€èƒŒæ™¯ä¿¡æ¯å’Œç›¸å…³æ–°é—»ï¼Œç»™å‡ºä¸“ä¸šã€å®¢è§‚çš„åˆ†æå»ºè®®ã€‚
"""

        # æ„å»ºå¢å¼ºä¸Šä¸‹æ–‡
        enhanced_context = []

        # æ·»åŠ å®æ—¶æ•°æ®
        if realtime_data:
            enhanced_context.append("=== å®æ—¶è‚¡ç¥¨æ•°æ® ===")
            for code, data in realtime_data.items():
                enhanced_context.append(f"è‚¡ç¥¨ {code}:")
                enhanced_context.append(f"- å½“å‰ä»·æ ¼: {data.get('current_price', 'N/A')}")
                enhanced_context.append(f"- æ¶¨è·Œå¹…: {data.get('change_percent', 'N/A')}%")
                enhanced_context.append(f"- æˆäº¤é‡: {data.get('volume', 'N/A')}")

        # æ·»åŠ RAGæ£€ç´¢çš„èƒŒæ™¯ä¿¡æ¯
        if rag_context:
            enhanced_context.append("\n=== ç›¸å…³èƒŒæ™¯ä¿¡æ¯ ===")
            for i, doc in enumerate(rag_context[:3], 1):
                enhanced_context.append(f"{i}. {doc.get('content', '')[:200]}...")

        # æ·»åŠ ç›¸å…³æ–°é—»
        if related_news:
            enhanced_context.append("\n=== ç›¸å…³æ–°é—» ===")
            for i, news in enumerate(related_news, 1):
                enhanced_context.append(f"{i}. {news.get('title', '')}")
                enhanced_context.append(f"   {news.get('summary', '')[:150]}...")

        # æ„å»ºå®Œæ•´Prompt
        full_prompt = f"""{base_system}

{chr(10).join(enhanced_context)}

=== ç”¨æˆ·é—®é¢˜ ===
{user_message}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯æä¾›ä¸“ä¸šåˆ†æ:
"""

        return full_prompt

    async def _generate_ai_response(self, prompt: str, model: str,
                                  temperature: float, max_tokens: int) -> Dict:
        """è°ƒç”¨AIæ¨¡å‹ç”Ÿæˆå›å¤"""
        try:
            response = await self.ollama_client.post(
                "/api/generate",
                json={
                    "model": model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": temperature,
                        "num_predict": max_tokens
                    }
                }
            )

            if response.status_code == 200:
                result = response.json()
                return {
                    "generated_text": result.get("response", ""),
                    "model_used": model,
                    "confidence_score": 0.85  # TODO: å®é™…ç½®ä¿¡åº¦è®¡ç®—
                }

        except Exception as e:
            print(f"AIå›å¤ç”Ÿæˆå¤±è´¥: {e}")

        return {
            "generated_text": "æŠ±æ­‰ï¼Œå½“å‰æ— æ³•ç”Ÿæˆå›å¤ï¼Œè¯·ç¨åå†è¯•ã€‚",
            "model_used": model,
            "confidence_score": 0.0
        }

    def _identify_data_sources(self, realtime_data: Dict, rag_context: List[Dict],
                              related_news: List[Dict]) -> List[str]:
        """è¯†åˆ«ä½¿ç”¨çš„æ•°æ®æº"""
        sources = []

        if realtime_data:
            sources.append("å®æ—¶è‚¡ç¥¨æ•°æ®")
        if rag_context:
            sources.append("å†å²åˆ†ææŠ¥å‘Š")
        if related_news:
            sources.append("ç›¸å…³æ–°é—»èµ„è®¯")

        return sources

# ä½¿ç”¨ç¤ºä¾‹
async def handle_enhanced_chat(request: EnhancedChatRequest):
    handler = EnhancedChatHandler()
    return await handler.process_enhanced_chat(request)
```

### ä¸“ä¸šé‡‘èå¯¹è¯æ¨¡æ¿
```python
class FinancialChatTemplates:
    """é‡‘èä¸“ä¸šå¯¹è¯æ¨¡æ¿åº“"""

    STOCK_ANALYSIS_TEMPLATE = """
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è‚¡ç¥¨åˆ†æå¸ˆã€‚ç”¨æˆ·è¯¢é—®å…³äº {stock_codes} çš„æŠ•èµ„å»ºè®®ã€‚

å®æ—¶æ•°æ®æ˜¾ç¤º:
{realtime_data_summary}

ç›¸å…³èƒŒæ™¯ä¿¡æ¯:
{rag_context_summary}

æœ€æ–°ç›¸å…³æ–°é—»:
{news_summary}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æ:
1. æŠ€æœ¯é¢åˆ†æ (ä»·æ ¼èµ°åŠ¿ã€æŠ€æœ¯æŒ‡æ ‡)
2. åŸºæœ¬é¢è¯„ä¼° (è´¢åŠ¡çŠ¶å†µã€ä¸šåŠ¡è¡¨ç°)
3. æ¶ˆæ¯é¢å½±å“ (æ”¿ç­–ã€æ–°é—»å¯¹è‚¡ä»·çš„å½±å“)
4. é£é™©æç¤ºå’ŒæŠ•èµ„å»ºè®®

ç”¨æˆ·é—®é¢˜: {user_message}
"""

    MARKET_OVERVIEW_TEMPLATE = """
ä½ æ˜¯å¸‚åœºåˆ†æä¸“å®¶ã€‚è¯·åŸºäºå½“å‰å¸‚åœºæ•°æ®å’Œæ–°é—»ä¿¡æ¯ï¼Œæä¾›å¸‚åœºæ•´ä½“èµ°åŠ¿åˆ†æã€‚

å½“å‰å¸‚åœºæ•°æ®:
{market_data}

é‡è¦æ–°é—»äº‹ä»¶:
{important_news}

è¯·åˆ†æ:
1. å¸‚åœºæ•´ä½“è¶‹åŠ¿
2. ä¸»è¦å½±å“å› ç´ 
3. æŠ•èµ„æœºä¼šå’Œé£é™©
4. åå¸‚é¢„æœŸ

ç”¨æˆ·é—®é¢˜: {user_message}
"""

    RISK_ASSESSMENT_TEMPLATE = """
ä½ æ˜¯é£é™©ç®¡ç†ä¸“å®¶ã€‚è¯·å¯¹ç”¨æˆ·çš„æŠ•èµ„é—®é¢˜è¿›è¡Œé£é™©è¯„ä¼°ã€‚

ç›¸å…³æ•°æ®:
{risk_data}

è¯·è¯„ä¼°:
1. å¸‚åœºé£é™©
2. ä¸ªè‚¡é£é™©
3. æµåŠ¨æ€§é£é™©
4. é£é™©æ§åˆ¶å»ºè®®

ç”¨æˆ·é—®é¢˜: {user_message}
"""
```

---

## ğŸš€ éƒ¨ç½²å’Œè¿ç»´è„šæœ¬

### æ¨¡å‹ä¸‹è½½è„šæœ¬ (customizations/models/model_downloader.py)
```python
#!/usr/bin/env python3
"""
Prism2 æ¨¡å‹ä¸‹è½½å’Œç®¡ç†è„šæœ¬
"""
import requests
import json
import subprocess
import time
from pathlib import Path

class OllamaModelManager:
    def __init__(self, ollama_url="http://localhost:11434"):
        self.ollama_url = ollama_url
        self.required_models = [
            "qwen2.5:7b",
            "deepseek-coder:1.3b",
            "bge-large-zh-v1.5"
        ]

    def pull_model(self, model_name):
        """ä¸‹è½½æŒ‡å®šæ¨¡å‹"""
        print(f"æ­£åœ¨ä¸‹è½½æ¨¡å‹: {model_name}")
        try:
            result = subprocess.run([
                "ollama", "pull", model_name
            ], capture_output=True, text=True, timeout=3600)

            if result.returncode == 0:
                print(f"âœ… æ¨¡å‹ {model_name} ä¸‹è½½æˆåŠŸ")
                return True
            else:
                print(f"âŒ æ¨¡å‹ {model_name} ä¸‹è½½å¤±è´¥: {result.stderr}")
                return False
        except subprocess.TimeoutExpired:
            print(f"â° æ¨¡å‹ {model_name} ä¸‹è½½è¶…æ—¶")
            return False

    def check_model_status(self, model_name):
        """æ£€æŸ¥æ¨¡å‹çŠ¶æ€"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags")
            if response.status_code == 200:
                models = response.json().get("models", [])
                for model in models:
                    if model.get("name") == model_name:
                        return True
            return False
        except:
            return False

    def setup_all_models(self):
        """è®¾ç½®æ‰€æœ‰å¿…éœ€çš„æ¨¡å‹"""
        print("ğŸš€ å¼€å§‹è®¾ç½®Prism2æ‰€éœ€çš„AIæ¨¡å‹...")

        for model in self.required_models:
            if not self.check_model_status(model):
                self.pull_model(model)
            else:
                print(f"âœ… æ¨¡å‹ {model} å·²å­˜åœ¨")

        print("ğŸ‰ æ¨¡å‹è®¾ç½®å®Œæˆ!")

if __name__ == "__main__":
    manager = OllamaModelManager()
    manager.setup_all_models()
```

### å¥åº·æ£€æŸ¥è„šæœ¬ (scripts/health_check.sh)
```bash
#!/bin/bash
# Open WebUI å¥åº·æ£€æŸ¥è„šæœ¬

set -e

WEBUI_URL="http://localhost:3001"
OLLAMA_URL="http://localhost:11434"
LOG_FILE="/var/log/prism2/webui-health.log"

# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p "$(dirname "$LOG_FILE")"

# æ—¥å¿—å‡½æ•°
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

# æ£€æŸ¥Open WebUIçŠ¶æ€
check_webui() {
    log "æ£€æŸ¥Open WebUIçŠ¶æ€..."

    if curl -f -s -o /dev/null "$WEBUI_URL/health"; then
        log "âœ… Open WebUI è¿è¡Œæ­£å¸¸"
        return 0
    else
        log "âŒ Open WebUI æ— å“åº”"
        return 1
    fi
}

# æ£€æŸ¥Ollamaè¿æ¥
check_ollama() {
    log "æ£€æŸ¥Ollamaè¿æ¥..."

    if curl -f -s -o /dev/null "$OLLAMA_URL/api/tags"; then
        log "âœ… Ollama è¿æ¥æ­£å¸¸"
        return 0
    else
        log "âŒ Ollama è¿æ¥å¤±è´¥"
        return 1
    fi
}

# æ£€æŸ¥æ¨¡å‹çŠ¶æ€
check_models() {
    log "æ£€æŸ¥æ¨¡å‹çŠ¶æ€..."

    local models=("qwen2.5:7b" "deepseek-coder:1.3b")
    local all_loaded=true

    for model in "${models[@]}"; do
        if curl -s "$OLLAMA_URL/api/tags" | jq -e ".models[] | select(.name == \"$model\")" > /dev/null; then
            log "âœ… æ¨¡å‹ $model å·²åŠ è½½"
        else
            log "âš ï¸ æ¨¡å‹ $model æœªåŠ è½½"
            all_loaded=false
        fi
    done

    if $all_loaded; then
        return 0
    else
        return 1
    fi
}

# ä¸»æ£€æŸ¥æµç¨‹
main() {
    log "å¼€å§‹Open WebUIå¥åº·æ£€æŸ¥..."

    local exit_code=0

    if ! check_webui; then
        exit_code=1
    fi

    if ! check_ollama; then
        exit_code=1
    fi

    if ! check_models; then
        exit_code=1
    fi

    if [ $exit_code -eq 0 ]; then
        log "ğŸ‰ æ‰€æœ‰æœåŠ¡è¿è¡Œæ­£å¸¸"
    else
        log "âš ï¸ å‘ç°æœåŠ¡å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"
    fi

    return $exit_code
}

# æ‰§è¡Œæ£€æŸ¥
main "$@"
```

---

## ğŸ”’ ç¯å¢ƒé…ç½®

### ç¯å¢ƒå˜é‡ (.env)
```bash
# Open WebUIé…ç½®
WEBUI_SECRET_KEY=your-super-secret-webui-key
WEBUI_NAME=Prism2 AI Lab
WEBUI_URL=http://localhost:3001

# è®¤è¯é…ç½®
ENABLE_SIGNUP=false
DEFAULT_USER_ROLE=user
ADMIN_EMAIL=admin@prism2.local
ADMIN_PASSWORD=your-admin-password

# Ollamaè¿æ¥é…ç½®
OLLAMA_BASE_URL=http://host.docker.internal:11434
ENABLE_OLLAMA_API=true

# === å¤–éƒ¨æœåŠ¡é›†æˆé…ç½® ===
STOCK_SERVICE_URL=http://host.docker.internal:8000
RAG_SERVICE_URL=http://host.docker.internal:8001
AUTH_SERVICE_URL=http://host.docker.internal:8004
NEWS_SERVICE_URL=http://host.docker.internal:8005

# RAGå¢å¼ºåŠŸèƒ½é…ç½®
ENABLE_RAG_ENHANCED_CHAT=true
RAG_CONTEXT_LIMIT=5
ENABLE_REALTIME_DATA=true
ENABLE_NEWS_INTEGRATION=true

# åŠŸèƒ½å¼€å…³ (é‡‘èåœºæ™¯ä¼˜åŒ–)
ENABLE_MODEL_FILTER=true
ENABLE_WEB_SEARCH=false
ENABLE_IMAGE_GENERATION=false
ENABLE_COMMUNITY_SHARING=false
ENABLE_STOCK_ANALYSIS_MODE=true
ENABLE_EXTERNAL_AUTH=true

# å­˜å‚¨é…ç½®
DATA_DIR=/app/backend/data
UPLOAD_DIR=/app/backend/data/uploads
MAX_FILE_SIZE=10MB

# è‡ªå®šä¹‰é…ç½®
CUSTOM_THEME_PATH=/app/backend/data/themes
DEFAULT_PROMPT_TEMPLATE_PATH=/app/backend/data/prompts

# æ€§èƒ½é…ç½®
MAX_CONCURRENT_REQUESTS=5
REQUEST_TIMEOUT=300
MODEL_LOAD_TIMEOUT=600

# å®‰å…¨é…ç½®
SESSION_DURATION=86400
CSRF_PROTECTION=true
RATE_LIMITING=true

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
LOG_FILE=/var/log/prism2/webui.log
```

---

## ğŸ“Š ç›‘æ§å’Œç»´æŠ¤

### å…³é”®æ€§èƒ½æŒ‡æ ‡
- **å“åº”æ—¶é—´**: é¡µé¢åŠ è½½å’ŒAPIå“åº”æ—¶é—´
- **å¹¶å‘ç”¨æˆ·**: åŒæ—¶åœ¨çº¿ç”¨æˆ·æ•°é‡
- **æ¨¡å‹ä½¿ç”¨**: å„æ¨¡å‹çš„ä½¿ç”¨é¢‘ç‡å’Œæ€§èƒ½
- **é”™è¯¯ç‡**: ç³»ç»Ÿé”™è¯¯å’Œç”¨æˆ·æ“ä½œå¤±è´¥ç‡

### ç»´æŠ¤ä»»åŠ¡
```bash
# å®šæœŸä»»åŠ¡ (crontab)
# æ¯å°æ—¶æ‰§è¡Œå¥åº·æ£€æŸ¥
0 * * * * /home/wyatt/prism2/open-webui/scripts/health_check.sh

# æ¯å¤©å¤‡ä»½æ•°æ®
0 2 * * * /home/wyatt/prism2/open-webui/scripts/backup.sh

# æ¯å‘¨æ¸…ç†æ—¥å¿—
0 3 * * 0 find /var/log/prism2 -name "*.log" -mtime +7 -delete
```

---

*æ–‡æ¡£æ›´æ–°æ—¶é—´: 2025-09-16*
*ä¸¥æ ¼éµå¾ªå¤–éƒ¨è®¾è®¡è§„èŒƒï¼Œç¡®ä¿æ¥å£ä¸€è‡´æ€§*