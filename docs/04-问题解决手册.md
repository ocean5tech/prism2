# 04-é—®é¢˜è§£å†³æ‰‹å†Œ

> **åŸºäºå®é™…é‡åˆ°é—®é¢˜çš„è§£å†³æ–¹æ¡ˆæ±‡æ€»**
>
> ä»LessonsLearned.mdå’Œå¼€å‘è¿‡ç¨‹ä¸­æ€»ç»“çš„å…³é”®é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

## ğŸš« ä»£ç†é…ç½®é—®é¢˜

### é—®é¢˜1: å…¬å¸ä»£ç†é˜»æ­¢localhostè®¿é—®
**ç°è±¡**: APIè°ƒç”¨è¿”å›403 Forbiddenï¼Œcurl localhostå¤±è´¥
```bash
curl: (7) Failed to connect to localhost port 8001
HTTP 403 Forbidden
```

**æ ¹æœ¬åŸå› **: å…¬å¸ä»£ç†è®¾ç½®å½±å“æœ¬åœ°æœåŠ¡é—´é€šä¿¡

**æ°¸ä¹…è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. ç¯å¢ƒå˜é‡é…ç½® (æ‰€æœ‰ç»ˆç«¯)
export no_proxy="localhost,127.0.0.1,::1,0.0.0.0"
export NO_PROXY="localhost,127.0.0.1,::1,0.0.0.0"

# 2. æ·»åŠ åˆ° ~/.bashrc
echo 'export no_proxy="localhost,127.0.0.1,::1,0.0.0.0"' >> ~/.bashrc
echo 'export NO_PROXY="localhost,127.0.0.1,::1,0.0.0.0"' >> ~/.bashrc

# 3. Docker Composeé…ç½®
environment:
  - no_proxy=localhost,127.0.0.1,::1,0.0.0.0
  - NO_PROXY=localhost,127.0.0.1,::1,0.0.0.0

# 4. éªŒè¯é…ç½®
curl -v http://localhost:8001/health
```

### é—®é¢˜2: PydanticéªŒè¯é”™è¯¯ - extra_forbidden
**ç°è±¡**: `Extra inputs are not permitted [type=extra_forbidden, input_value='localhost,127.0.0.1,::1']`

**è§£å†³æ–¹æ¡ˆ**: ä»Pydanticæ¨¡å‹ä¸­æ’é™¤ä»£ç†ç›¸å…³ç¯å¢ƒå˜é‡
```python
# app/core/config.py
class Settings(BaseSettings):
    # ä¸šåŠ¡é…ç½®
    database_url: str
    redis_url: str

    class Config:
        env_file = ".env"
        # å¿½ç•¥ä»£ç†ç›¸å…³å˜é‡
        extra = "ignore"
```

## ğŸ—„ï¸ æ•°æ®åº“è¿æ¥é—®é¢˜

### é—®é¢˜3: PostgreSQLè®¤è¯å¤±è´¥
**ç°è±¡**: `password authentication failed for user 'postgres'`

**è¯Šæ–­æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥å®¹å™¨çŠ¶æ€
docker ps | grep postgres

# 2. æ£€æŸ¥ç¯å¢ƒå˜é‡
docker exec prism2-postgres env | grep POSTGRES

# 3. æµ‹è¯•è¿æ¥
docker exec prism2-postgres pg_isready -U prism2
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ç¡®ä¿ç¯å¢ƒå˜é‡æ­£ç¡®
DATABASE_URL=postgresql://prism2:prism2_secure_password@localhost:5432/prism2

# é‡ç½®å®¹å™¨
docker-compose down postgres
docker volume rm prism2_postgres_data
docker-compose up -d postgres
```

### é—®é¢˜4: æ•°æ®åº“è¿æ¥æ± è€—å°½
**ç°è±¡**: `QueuePool limit of size 20 overflow 30 reached`

**è§£å†³æ–¹æ¡ˆ**: ä¼˜åŒ–è¿æ¥æ± é…ç½®
```python
from sqlalchemy import create_engine

engine = create_engine(
    DATABASE_URL,
    pool_size=20,           # åŸºç¡€è¿æ¥æ•°
    max_overflow=30,        # é¢å¤–è¿æ¥æ•°
    pool_timeout=30,        # è¿æ¥è¶…æ—¶
    pool_recycle=3600,      # è¿æ¥å›æ”¶æ—¶é—´
    pool_pre_ping=True      # è¿æ¥éªŒè¯
)
```

## ğŸ”— å‘é‡æ•°æ®åº“é—®é¢˜

### é—®é¢˜5: ChromaDBå®¹å™¨å¯åŠ¨å¤±è´¥å’Œè¿æ¥é—®é¢˜

#### 5.1 ChromaDB APIè¿”å›403 Forbidden
**ç°è±¡**:
```bash
curl http://localhost:8000/api/v1/heartbeat
# è¿”å›: HTTP/1.0 403 Forbidden
```

**æ ¹æœ¬åŸå› **: å®¹å™¨å¯åŠ¨æ—¶ç»§æ‰¿å®¿ä¸»æœºä»£ç†ç¯å¢ƒå˜é‡ï¼Œå¯¼è‡´å†…éƒ¨ç½‘ç»œè¢«æ‹¦æˆª

**Docker Composeè§£å†³æ–¹æ¡ˆ**:
```yaml
# docker-compose.ymlä¸­ChromaDBé…ç½®
chromadb:
  image: chromadb/chroma:latest
  environment:
    - CHROMA_SERVER_HOST=0.0.0.0
    - CHROMA_SERVER_HTTP_PORT=8000
    - PERSIST_DIRECTORY=/chroma/chroma
    # æ˜ç¡®æ¸…é™¤ä»£ç†è®¾ç½®
    - http_proxy=
    - https_proxy=
    - HTTP_PROXY=
    - HTTPS_PROXY=
  volumes:
    - chromadb_data:/chroma/chroma
```

#### 5.2 ChromaDBè¿æ¥å†²çª (åº”ç”¨å±‚)
**ç°è±¡**: `An instance of Chroma already exists for localhost:8000 with different settings`

**è§£å†³æ–¹æ¡ˆ**: å®ç°æ­£ç¡®çš„å•ä¾‹æ¨¡å¼ + DockeræœåŠ¡å‘ç°
```python
class VectorService:
    _instance = None
    _initialized = False

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if not self._initialized:
            # ä½¿ç”¨DockeræœåŠ¡åè€Œélocalhost
            self.client = chromadb.HttpClient(
                host=os.getenv("CHROMADB_HOST", "chromadb"),
                port=int(os.getenv("CHROMADB_PORT", "8000")),
                settings=Settings(allow_reset=True)
            )
            self._initialized = True
```

#### 5.3 ChromaDBä¾èµ–é—®é¢˜ (æ—§ç‰ˆæœ¬é—®é¢˜)
**ç°è±¡**: æœ¬åœ°å®‰è£…chromadbæ—¶å„ç§ä¾èµ–å†²çª

**Dockerä¼˜åŠ¿**:
- âœ… å®˜æ–¹é•œåƒåŒ…å«æ‰€æœ‰ä¾èµ–
- âœ… ç‰ˆæœ¬é”å®šï¼Œæ— å†²çª
- âœ… éš”ç¦»ç¯å¢ƒï¼Œä¸å½±å“å®¿ä¸»æœº
- âœ… ä¸€é”®å¯åŠ¨ï¼Œæ— éœ€å¤æ‚é…ç½®

**éªŒè¯å‘½ä»¤**:
```bash
# æ£€æŸ¥ChromaDBå®¹å™¨çŠ¶æ€
docker-compose ps chromadb

# æµ‹è¯•APIè¿æ¥
curl http://localhost:8000/api/v1/heartbeat

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker-compose logs chromadb
```

### é—®é¢˜6: UUIDå­—æ®µéªŒè¯é”™è¯¯
**ç°è±¡**: `Input should be a valid string [type=string_type, input_value=UUID(...)]`

**è§£å†³æ–¹æ¡ˆ**: æ­£ç¡®å¤„ç†UUIDç±»å‹è½¬æ¢
```python
# APIå“åº”ä¸­è½¬æ¢UUIDä¸ºå­—ç¬¦ä¸²
response_data = {
    "task_id": str(task.task_id),  # UUID -> str
    "status": task.status
}

# æ•°æ®åº“æŸ¥è¯¢ä¸­ä½¿ç”¨UUIDç±»å‹
task = session.query(BootstrapTask).filter(
    BootstrapTask.task_id == uuid.UUID(task_id)
).first()
```

## ğŸ“¦ ä¾èµ–ç®¡ç†é—®é¢˜

### é—®é¢˜7: AKShareä¾èµ–ç¼ºå¤±
**ç°è±¡**: `ModuleNotFoundError: No module named 'akshare'`

**è§£å†³æ–¹æ¡ˆ**: æ·»åŠ åˆ°requirements.txt
```txt
# requirements.txt æ–°å¢
akshare>=1.12.0
pandas>=2.0.0
requests>=2.31.0
```

### é—®é¢˜8: åŒ…ç‰ˆæœ¬å†²çª
**ç°è±¡**: ä¸åŒåŒ…è¦æ±‚ä¸å…¼å®¹çš„ä¾èµ–ç‰ˆæœ¬

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨å…¼å®¹ç‰ˆæœ¬èŒƒå›´
```txt
# ä½¿ç”¨å…¼å®¹æ€§èŒƒå›´è€Œéå›ºå®šç‰ˆæœ¬
fastapi>=0.104.0,<0.105.0
uvicorn>=0.24.0,<0.25.0
pydantic>=2.5.0,<2.6.0
```

## ğŸŒ APIæœåŠ¡é—®é¢˜

### é—®é¢˜9: å¤–éƒ¨APIè¯·æ±‚å¤±è´¥
**ç°è±¡**: RSSæºè¿”å›403æˆ–è¶…æ—¶

**è¯Šæ–­å’Œè§£å†³**:
```python
# 1. æµ‹è¯•APIå¯ç”¨æ€§
import requests

def test_data_sources():
    sources = {
        "æ–°æµªè´¢ç»RSS": "http://rss.sina.com.cn/roll/finance/hot_roll.xml",
        "åŒèŠ±é¡ºè´¢ç»": "https://news.10jqka.com.cn/rss_info.php"
    }

    for name, url in sources.items():
        try:
            response = requests.get(url, timeout=10)
            print(f"âœ… {name}: {response.status_code}")
        except Exception as e:
            print(f"âŒ {name}: {e}")

# 2. ç»“æœ: åªæœ‰æ–°æµªè´¢ç»å¯ç”¨ï¼Œå…¶ä»–å·²å¤±æ•ˆ
# 3. æ›´æ–°æ•°æ®æºé…ç½®ï¼Œç§»é™¤å¤±æ•ˆæº
```

### é—®é¢˜10: WebSocketè¿æ¥æ–­å¼€
**ç°è±¡**: å‰ç«¯WebSocketé¢‘ç¹æ–­å¼€é‡è¿

**è§£å†³æ–¹æ¡ˆ**: é…ç½®Nginx WebSocketä»£ç†
```nginx
location /ws/ {
    proxy_pass http://backend;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "upgrade";
    proxy_set_header Host $host;
    proxy_cache_bypass $http_upgrade;
}
```

## ğŸ”„ æ‰¹å¤„ç†ä»»åŠ¡é—®é¢˜

### é—®é¢˜11: å¤œé—´ä»»åŠ¡å†…å­˜æ³„æ¼
**ç°è±¡**: é•¿æ—¶é—´è¿è¡Œåå†…å­˜ä½¿ç”¨æŒç»­å¢é•¿

**è§£å†³æ–¹æ¡ˆ**: å®ç°å†…å­˜ç®¡ç†
```python
import gc
import psutil

def monitor_memory():
    process = psutil.Process()
    memory_mb = process.memory_info().rss / 1024 / 1024
    if memory_mb > 1024:  # è¶…è¿‡1GB
        gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
        print(f"Memory: {memory_mb:.2f}MB, GC triggered")

# åœ¨å¾ªç¯å¤„ç†ä¸­è°ƒç”¨
for batch in data_batches:
    process_batch(batch)
    monitor_memory()
```

### é—®é¢˜12: APIé™æµé—®é¢˜
**ç°è±¡**: AKShare APIè¿”å›429 Too Many Requests

**è§£å†³æ–¹æ¡ˆ**: å®ç°æ™ºèƒ½é™æµ
```python
import time
from functools import wraps

def rate_limit(calls_per_minute=60):
    def decorator(func):
        last_called = [0.0]

        @wraps(func)
        def wrapper(*args, **kwargs):
            elapsed = time.time() - last_called[0]
            wait_time = 60.0 / calls_per_minute

            if elapsed < wait_time:
                time.sleep(wait_time - elapsed)

            last_called[0] = time.time()
            return func(*args, **kwargs)

        return wrapper
    return decorator

@rate_limit(calls_per_minute=30)  # AKShareé™åˆ¶
def get_stock_data(code):
    return ak.stock_zh_a_hist(symbol=code)
```

## ğŸ³ Dockeréƒ¨ç½²é—®é¢˜

### é—®é¢˜13: å®¹å™¨å¯åŠ¨é¡ºåºä¾èµ–
**ç°è±¡**: åº”ç”¨æœåŠ¡åœ¨æ•°æ®åº“æœªå°±ç»ªæ—¶å¯åŠ¨å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨å¥åº·æ£€æŸ¥å’Œä¾èµ–ç­‰å¾…
```yaml
services:
  backend:
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
```

### é—®é¢˜14: æ•°æ®å·æƒé™é—®é¢˜
**ç°è±¡**: `Permission denied` è®¿é—®æŒ‚è½½çš„æ•°æ®ç›®å½•

**è§£å†³æ–¹æ¡ˆ**: è®¾ç½®æ­£ç¡®çš„ç”¨æˆ·å’Œæƒé™
```yaml
services:
  app:
    user: "${UID}:${GID}"
    volumes:
      - ./data:/app/data:rw
```

## ğŸš¨ ç´§æ€¥é—®é¢˜å¤„ç†æµç¨‹

### ç³»ç»Ÿå®Œå…¨æ— å“åº”
```bash
# 1. æ£€æŸ¥ç³»ç»Ÿèµ„æº
htop
df -h

# 2. æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker-compose ps

# 3. æŸ¥çœ‹æœåŠ¡æ—¥å¿—
docker-compose logs --tail=100 backend

# 4. é‡å¯é—®é¢˜æœåŠ¡
docker-compose restart backend

# 5. å¦‚ä»æ— å“åº”ï¼Œå®Œå…¨é‡å¯
docker-compose down
docker-compose up -d
```

### æ•°æ®åº“æ•°æ®æŸå
```bash
# 1. ç«‹å³åœæ­¢å†™å…¥
docker-compose stop backend rag-service

# 2. å¤‡ä»½å½“å‰æ•°æ®
docker exec prism2-postgres pg_dump -U prism2 prism2 > backup_$(date +%Y%m%d_%H%M%S).sql

# 3. æ£€æŸ¥æ•°æ®åº“å®Œæ•´æ€§
docker exec prism2-postgres vacuumdb -U prism2 --analyze --verbose prism2

# 4. ä»å¤‡ä»½æ¢å¤ (å¦‚éœ€è¦)
docker exec -i prism2-postgres psql -U prism2 prism2 < backup_file.sql
```

---

**ğŸ“… åˆ›å»ºæ—¶é—´**: 2025-09-18
**ğŸ“Š é—®é¢˜è¦†ç›–ç‡**: åŸºäºå®é™…å¼€å‘ä¸­é‡åˆ°çš„æ ¸å¿ƒé—®é¢˜
**ğŸ”„ æ›´æ–°ç­–ç•¥**: é‡åˆ°æ–°é—®é¢˜ç«‹å³æ›´æ–°æ­¤æ–‡æ¡£