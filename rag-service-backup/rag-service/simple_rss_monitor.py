#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆRSSç›‘æ§ç³»ç»Ÿ
æ¼”ç¤ºè´¢ç»RSSç›‘æ§åŠŸèƒ½å’ŒRAGæ•°æ®åº“æ›´æ–°
"""

import sys
import os
sys.path.append('/home/wyatt/prism2/rag-service')

import chromadb
import json
from datetime import datetime, timedelta
from typing import List, Dict
import hashlib
import time
import jieba
from sklearn.feature_extraction.text import TfidfVectorizer
import random
from archive_manager import ArchiveManager

class SimpleRSSMonitor:
    def __init__(self):
        # Clear proxy variables
        for proxy_var in ['http_proxy', 'https_proxy', 'HTTP_PROXY', 'HTTPS_PROXY']:
            if proxy_var in os.environ:
                del os.environ[proxy_var]

        self.client = None
        self.collection = None
        self.vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))
        self.archive_manager = ArchiveManager()

        # æ¨¡æ‹Ÿè´¢ç»æ–°é—»æ•°æ®
        self.mock_news_templates = [
            {
                'title': 'å¤®è¡Œå®£å¸ƒä¸‹è°ƒå­˜æ¬¾å‡†å¤‡é‡‘ç‡0.5ä¸ªç™¾åˆ†ç‚¹',
                'content': 'ä¸­å›½äººæ°‘é“¶è¡Œå†³å®šäº2025å¹´1æœˆ15æ—¥ä¸‹è°ƒé‡‘èæœºæ„å­˜æ¬¾å‡†å¤‡é‡‘ç‡0.5ä¸ªç™¾åˆ†ç‚¹ï¼Œé‡Šæ”¾é•¿æœŸèµ„é‡‘çº¦1ä¸‡äº¿å…ƒã€‚æ­¤æ¬¡é™å‡†æ—¨åœ¨ä¿æŒé“¶è¡Œä½“ç³»æµåŠ¨æ€§åˆç†å……è£•ï¼Œæ”¯æŒå®ä½“ç»æµå‘å±•ã€‚å¸‚åœºåˆ†æè®¤ä¸ºï¼Œè¿™å°†æœ‰åˆ©äºé™ä½é“¶è¡Œèµ„é‡‘æˆæœ¬ï¼Œå¼•å¯¼è´·æ¬¾åˆ©ç‡è¿›ä¸€æ­¥ä¸‹è¡Œï¼Œå¯¹è‚¡å¸‚æ„æˆåˆ©å¥½ã€‚',
                'source': 'å¤®è§†è´¢ç»',
                'importance': 9,
                'keywords': ['å¤®è¡Œ', 'é™å‡†', 'æµåŠ¨æ€§', 'å®ä½“ç»æµ', 'åˆ©å¥½']
            },
            {
                'title': 'ç§‘æŠ€è‚¡é›†ä½“å¤§æ¶¨ï¼ŒAIæ¿å—å†ç°æ¶¨åœæ½®',
                'content': 'ä»Šæ—¥Aè‚¡å¸‚åœºç§‘æŠ€è‚¡è¡¨ç°å¼ºåŠ²ï¼Œäººå·¥æ™ºèƒ½ã€èŠ¯ç‰‡ã€è½¯ä»¶ç­‰æ¿å—å…¨çº¿ä¸Šæ¶¨ã€‚å…¶ä¸­AIæ¦‚å¿µè‚¡æ¶¨å¹…å±…å‰ï¼Œå¤šåªä¸ªè‚¡æ¶¨åœã€‚åˆ†æå¸ˆè®¤ä¸ºï¼Œéšç€AIæŠ€æœ¯ä¸æ–­çªç ´å’Œåº”ç”¨åœºæ™¯æ‰©å¤§ï¼Œç›¸å…³ä¸Šå¸‚å…¬å¸æœ‰æœ›è¿æ¥ä¸šç»©å’Œä¼°å€¼åŒé‡æå‡ã€‚æŠ•èµ„è€…åº”å…³æ³¨å…·å¤‡æ ¸å¿ƒæŠ€æœ¯å’Œå•†ä¸šåŒ–èƒ½åŠ›çš„ä¼˜è´¨æ ‡çš„ã€‚',
                'source': 'è¯åˆ¸æ—¶æŠ¥',
                'importance': 8,
                'keywords': ['ç§‘æŠ€è‚¡', 'AI', 'æ¶¨åœ', 'èŠ¯ç‰‡', 'æŠ•èµ„æœºä¼š']
            },
            {
                'title': 'æ–°èƒ½æºæ±½è½¦é”€é‡åˆ›æ–°é«˜ï¼Œäº§ä¸šé“¾å…¬å¸å—ç›Š',
                'content': 'æ®ä¸­æ±½åæ•°æ®æ˜¾ç¤ºï¼Œ2024å¹´æ–°èƒ½æºæ±½è½¦é”€é‡åŒæ¯”å¢é•¿35%ï¼Œåˆ›å†å²æ–°é«˜ã€‚åŠ¨åŠ›ç”µæ± ã€å……ç”µæ¡©ã€æ™ºèƒ½é©¾é©¶ç­‰äº§ä¸šé“¾å„ç¯èŠ‚å‡å®ç°å¿«é€Ÿå‘å±•ã€‚æœºæ„é¢„æµ‹ï¼Œéšç€æŠ€æœ¯è¿›æ­¥å’Œæˆæœ¬ä¸‹é™ï¼Œæ–°èƒ½æºæ±½è½¦æ¸—é€ç‡å°†æŒç»­æå‡ï¼Œç›¸å…³äº§ä¸šé“¾å…¬å¸é•¿æœŸæˆé•¿ç©ºé—´å¹¿é˜”ã€‚',
                'source': 'ç¬¬ä¸€è´¢ç»',
                'importance': 7,
                'keywords': ['æ–°èƒ½æºæ±½è½¦', 'é”€é‡', 'äº§ä¸šé“¾', 'åŠ¨åŠ›ç”µæ± ', 'æˆé•¿ç©ºé—´']
            },
            {
                'title': 'æˆ¿åœ°äº§æ”¿ç­–æŒç»­ä¼˜åŒ–ï¼Œä¸€çº¿åŸå¸‚æˆäº¤é‡å›å‡',
                'content': 'è¿‘æœŸå¤šä¸ªä¸€çº¿åŸå¸‚è¿›ä¸€æ­¥ä¼˜åŒ–æˆ¿åœ°äº§è°ƒæ§æ”¿ç­–ï¼ŒåŒ…æ‹¬é™ä½é¦–ä»˜æ¯”ä¾‹ã€æ”¾å®½è´­æˆ¿é™åˆ¶ç­‰æªæ–½ã€‚æ•°æ®æ˜¾ç¤ºï¼Œæ”¿ç­–è°ƒæ•´åä¸€çº¿åŸå¸‚æ–°æˆ¿å’ŒäºŒæ‰‹æˆ¿æˆäº¤é‡å‡æœ‰æ˜æ˜¾å›å‡ã€‚ä¸šå†…ä¸“å®¶è¡¨ç¤ºï¼Œæ”¿ç­–æ”¯æŒæœ‰åŠ©äºæˆ¿åœ°äº§å¸‚åœºä¼ç¨³å›å‡ï¼Œä½†ä»éœ€å…³æ³¨åç»­æ”¿ç­–æ‰§è¡Œæƒ…å†µã€‚',
                'source': 'ç»æµæ—¥æŠ¥',
                'importance': 6,
                'keywords': ['æˆ¿åœ°äº§', 'æ”¿ç­–ä¼˜åŒ–', 'æˆäº¤é‡', 'ä¸€çº¿åŸå¸‚', 'ä¼ç¨³']
            },
            {
                'title': 'æ¶ˆè´¹æ•°æ®å‘å¥½ï¼Œå†…éœ€æ½œåŠ›æŒç»­é‡Šæ”¾',
                'content': 'å›½å®¶ç»Ÿè®¡å±€å…¬å¸ƒçš„æœ€æ–°æ•°æ®æ˜¾ç¤ºï¼Œç¤¾ä¼šæ¶ˆè´¹å“é›¶å”®æ€»é¢åŒæ¯”å¢é•¿7.8%ï¼Œæ¶ˆè´¹å¸‚åœºå‘ˆç°ç¨³æ­¥å›å‡æ€åŠ¿ã€‚å…¶ä¸­ï¼ŒæœåŠ¡æ¶ˆè´¹ã€ç»¿è‰²æ¶ˆè´¹ã€æ•°å­—æ¶ˆè´¹ç­‰æ–°å…´æ¶ˆè´¹é¢†åŸŸè¡¨ç°çªå‡ºã€‚ä¸“å®¶è®¤ä¸ºï¼Œéšç€ä¿ƒæ¶ˆè´¹æ”¿ç­–æŒç»­å‘åŠ›ï¼Œå†…éœ€å¸‚åœºæ½œåŠ›å°†è¿›ä¸€æ­¥é‡Šæ”¾ï¼Œä¸ºç»æµå¢é•¿æä¾›é‡è¦æ”¯æ’‘ã€‚',
                'source': 'æ–°åè´¢ç»',
                'importance': 7,
                'keywords': ['æ¶ˆè´¹æ•°æ®', 'å†…éœ€', 'é›¶å”®æ€»é¢', 'æ–°å…´æ¶ˆè´¹', 'ç»æµå¢é•¿']
            }
        ]

    def connect_to_chromadb(self):
        """è¿æ¥åˆ°ChromaDB"""
        try:
            self.client = chromadb.HttpClient(host='localhost', port=8000)
            self.client.heartbeat()

            collection_name = "financial_rss_news"
            try:
                # å°è¯•åˆ é™¤æ—§é›†åˆä»¥é¿å…ç»´åº¦å†²çª
                try:
                    old_collection = self.client.get_collection(collection_name)
                    self.client.delete_collection(collection_name)
                    print("ğŸ—‘ï¸ æ¸…ç†æ—§é›†åˆ")
                except:
                    pass

                # åˆ›å»ºæ–°é›†åˆ
                self.collection = self.client.create_collection(
                    name=collection_name,
                    metadata={"description": "Financial RSS news documents"}
                )
                print("ğŸ“ åˆ›å»ºæ–°é›†åˆ")

            except Exception as e:
                print(f"é›†åˆæ“ä½œå¤±è´¥: {e}")
                return False

            print("âœ… è¿æ¥åˆ°ChromaDBæˆåŠŸ")
            return True

        except Exception as e:
            print(f"âŒ è¿æ¥ChromaDBå¤±è´¥: {e}")
            return False

    def chinese_tokenize(self, text: str) -> str:
        """ä¸­æ–‡åˆ†è¯"""
        return ' '.join(jieba.cut(text))

    def create_tfidf_vector(self, text: str) -> List[float]:
        """åˆ›å»ºTF-IDFå‘é‡"""
        try:
            processed_text = self.chinese_tokenize(text)
            try:
                vector = self.vectorizer.transform([processed_text])
                return vector.toarray()[0].tolist()
            except:
                # é‡æ–°è®­ç»ƒå‘é‡åŒ–å™¨
                all_texts = [self.chinese_tokenize(template['content']) for template in self.mock_news_templates]
                all_texts.append(processed_text)
                self.vectorizer.fit(all_texts)
                vector = self.vectorizer.transform([processed_text])
                return vector.toarray()[0].tolist()
        except Exception as e:
            print(f"âš ï¸ å‘é‡åŒ–å¤±è´¥: {e}")
            return [0.0] * 1000

    def generate_mock_articles(self, count: int = 3) -> List[Dict]:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ–°é—»æ–‡ç« """
        articles = []

        for i in range(count):
            # éšæœºé€‰æ‹©æ¨¡æ¿
            template = random.choice(self.mock_news_templates)

            # æ·»åŠ æ—¶é—´å˜åŒ–
            pub_time = datetime.now() - timedelta(hours=random.randint(0, 12))

            article = {
                'title': template['title'],
                'content': template['content'],
                'url': f"https://finance.example.com/news/{random.randint(100000, 999999)}",
                'source': template['source'],
                'published_time': pub_time.isoformat(),
                'importance': template['importance'],
                'keywords': template['keywords'],
                'summary': template['content'][:100] + '...'
            }

            articles.append(article)

        return articles

    def store_articles_to_rag(self, articles: List[Dict]):
        """å°†æ–‡ç« å­˜å‚¨åˆ°RAGæ•°æ®åº“"""
        if not self.collection:
            print("âŒ RAGæ•°æ®åº“æœªè¿æ¥")
            return

        stored_count = 0

        for article in articles:
            try:
                # åˆ›å»ºæ–‡æ¡£ID
                doc_id = f"rss_{hashlib.md5(article['url'].encode()).hexdigest()[:12]}"

                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                try:
                    existing = self.collection.get(ids=[doc_id])
                    if existing['ids']:
                        continue
                except:
                    pass

                # å‡†å¤‡æ–‡æ¡£å†…å®¹
                document_content = f"""æ ‡é¢˜: {article['title']}

å†…å®¹: {article['content']}

å…³é”®è¯: {', '.join(article['keywords'])}

æ¥æº: {article['source']}"""

                # åˆ›å»ºå‘é‡
                embedding = self.create_tfidf_vector(document_content)

                # å‡†å¤‡å…ƒæ•°æ®
                metadata = {
                    'source_type': 'rss_news',
                    'source_name': article['source'],
                    'url': article['url'],
                    'timestamp': datetime.now().isoformat(),
                    'published_time': article['published_time'],
                    'importance': article['importance'],
                    'keywords': json.dumps(article['keywords'], ensure_ascii=False),
                    'category': 'financial_news'
                }

                # å­˜å‚¨åˆ°ChromaDB
                self.collection.add(
                    documents=[document_content],
                    embeddings=[embedding],
                    metadatas=[metadata],
                    ids=[doc_id]
                )

                stored_count += 1
                print(f"   âœ… å­˜å‚¨: {article['title'][:30]}...")

            except Exception as e:
                print(f"âš ï¸ å­˜å‚¨æ–‡ç« å¤±è´¥: {e}")
                continue

        print(f"âœ… æˆåŠŸå­˜å‚¨ {stored_count} ç¯‡æ–°æ–‡ç« åˆ°RAGæ•°æ®åº“")

        # ä¿å­˜åˆ°å½’æ¡£
        if articles:
            archive_metadata = {
                'source': 'rss_monitor',
                'collection_name': 'financial_rss_news',
                'stored_count': stored_count,
                'total_articles': len(articles)
            }

            self.archive_manager.save_archive(
                data=articles,
                data_type='rss_news',
                metadata=archive_metadata
            )

    def simulate_monitoring_cycle(self, article_count: int = 5):
        """æ¨¡æ‹Ÿä¸€æ¬¡ç›‘æ§å‘¨æœŸ"""
        print(f"ğŸš€ å¼€å§‹RSSç›‘æ§æ¨¡æ‹Ÿ")
        print(f"ğŸ“¡ æ¨¡æ‹Ÿæ”¶é›† {article_count} ç¯‡è´¢ç»æ–°é—»")
        print("-" * 60)

        start_time = time.time()

        # ç”Ÿæˆæ¨¡æ‹Ÿæ–‡ç« 
        articles = self.generate_mock_articles(article_count)

        print(f"ğŸ“° ç”Ÿæˆäº† {len(articles)} ç¯‡æ¨¡æ‹Ÿæ–°é—»:")
        for i, article in enumerate(articles, 1):
            print(f"   {i}. {article['title']} (é‡è¦æ€§: {article['importance']}/10)")

        print(f"\nğŸ’¾ å¼€å§‹å­˜å‚¨åˆ°RAGæ•°æ®åº“...")

        # å­˜å‚¨åˆ°RAGæ•°æ®åº“
        self.store_articles_to_rag(articles)

        end_time = time.time()
        duration = end_time - start_time

        print(f"\nâ±ï¸ ç›‘æ§å‘¨æœŸå®Œæˆï¼Œè€—æ—¶: {duration:.2f} ç§’")
        print(f"ğŸ“Š æœ¬æ¬¡æ›´æ–°ç»Ÿè®¡:")
        print(f"   - æ–°å¢æ–‡ç« : {len(articles)} ç¯‡")
        print(f"   - å¹³å‡é‡è¦æ€§: {sum(a['importance'] for a in articles) / len(articles):.1f}/10")
        print(f"   - æ—¶é—´èŒƒå›´: æœ€è¿‘12å°æ—¶å†…")

    def show_database_status(self):
        """æ˜¾ç¤ºæ•°æ®åº“çŠ¶æ€"""
        if not self.collection:
            print("âŒ RAGæ•°æ®åº“æœªè¿æ¥")
            return

        try:
            count = self.collection.count()
            print(f"\nğŸ“Š RAGæ•°æ®åº“çŠ¶æ€:")
            print(f"   - æ€»æ–‡æ¡£æ•°: {count}")

            if count > 0:
                # è·å–æœ€è¿‘çš„æ–‡æ¡£
                results = self.collection.get(
                    limit=5,
                    include=['documents', 'metadatas']
                )

                print(f"   - æœ€è¿‘æ–‡æ¡£é¢„è§ˆ:")
                for i, doc_id in enumerate(results['ids'][:3]):
                    metadata = results['metadatas'][i] if results['metadatas'] else {}
                    doc_content = results['documents'][i] if results['documents'] else ''

                    title = doc_content.split('\n')[0].replace('æ ‡é¢˜: ', '') if doc_content else 'Unknown'
                    source = metadata.get('source_name', 'Unknown')
                    importance = metadata.get('importance', 'N/A')

                    print(f"     {i+1}. {title[:40]}... (æ¥æº: {source}, é‡è¦æ€§: {importance})")

        except Exception as e:
            print(f"âŒ è·å–æ•°æ®åº“çŠ¶æ€å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ RSSç›‘æ§ç³»ç»Ÿæ¼”ç¤º")
    print("="*60)

    monitor = SimpleRSSMonitor()

    if not monitor.connect_to_chromadb():
        return

    # æ˜¾ç¤ºå½“å‰æ•°æ®åº“çŠ¶æ€
    monitor.show_database_status()

    print(f"\n" + "="*60)

    # è¿è¡Œæ¨¡æ‹Ÿç›‘æ§
    if len(sys.argv) > 1:
        try:
            article_count = int(sys.argv[1])
        except ValueError:
            article_count = 5
    else:
        article_count = 5

    monitor.simulate_monitoring_cycle(article_count)

    # æ˜¾ç¤ºæ›´æ–°åçš„æ•°æ®åº“çŠ¶æ€
    print(f"\n" + "="*60)
    monitor.show_database_status()

    print(f"\nğŸ‰ RSSç›‘æ§æ¼”ç¤ºå®Œæˆ!")
    print(f"ğŸ’¡ å®é™…ä½¿ç”¨æ—¶ï¼Œå¯ä»¥:")
    print(f"   - é…ç½®çœŸå®çš„RSSæº")
    print(f"   - è®¾ç½®å®šæ—¶ä»»åŠ¡(å¦‚æ¯30åˆ†é’Ÿ)")
    print(f"   - æ·»åŠ å†…å®¹è´¨é‡è¿‡æ»¤")
    print(f"   - å®ç°å¢é‡æ›´æ–°ç­–ç•¥")

if __name__ == "__main__":
    main()